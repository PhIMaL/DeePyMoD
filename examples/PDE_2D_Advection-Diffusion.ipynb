{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # 2D Advection-Diffusion equation\n",
    "\n",
    "# in this notebook we provide a simple example of the DeepMoD algorithm and apply it on the 2D advection-diffusion equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# DeepMoD functions\n",
    "\n",
    "from deepymod import DeepMoD\n",
    "from deepymod.data import Dataset, get_train_test_loader\n",
    "from deepymod.data.samples import Subsample_random\n",
    "from deepymod.model.func_approx import NN\n",
    "from deepymod.model.library import Library2D\n",
    "from deepymod.model.constraint import LeastSquares\n",
    "from deepymod.model.sparse_estimators import Threshold, PDEFIND\n",
    "from deepymod.training import train\n",
    "from deepymod.training.sparsity_scheduler import TrainTestPeriodic\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Configuring GPU or CPU\n",
    "#if torch.cuda.is_available():\n",
    "#    device = \"cuda\"\n",
    "#else:\n",
    "device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "Next, we prepare the dataset. In order to do so, we write a \n",
    "function that loads the data from the matlab file, reshapes it into a shape \n",
    "we desire and then return it in a coordinate, data format. Where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    data = loadmat(\"data/advection_diffusion.mat\")\n",
    "    usol = np.real(data[\"Expression1\"]).astype(\"float32\")\n",
    "    usol = usol.reshape((51, 51, 61, 4))\n",
    "    x_v= usol[:,:,:,0]\n",
    "    y_v = usol[:,:,:,1]\n",
    "    t_v = usol[:,:,:,2]\n",
    "    u_v = usol[:,:,:,3]\n",
    "    coords = torch.from_numpy(np.transpose((t_v.flatten(),x_v.flatten(), y_v.flatten())))\n",
    "    data = torch.from_numpy(usol[:, :, :, 3].reshape(-1, 1))\n",
    "    print(\"The raw data has shape {}\".format(data.shape))\n",
    "    return coords, data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we pass this function to the dataset class, which then adds noise to it, normalizes the coordinates and performs random subsampling to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw data has shape torch.Size([158661, 1])\n",
      "Dataset is using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(\n",
    "    create_data,\n",
    "    preprocess_kwargs={\n",
    "        \"noise_level\": 0.1,\n",
    "        \"normalize_coords\": True,\n",
    "        \"normalize_data\": True,\n",
    "    },\n",
    "    subsampler=Subsample_random,\n",
    "    subsampler_kwargs={\"number_of_samples\": 2500},\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the dataset for three different time-points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = get_train_test_loader(dataset, train_test_split=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of DeepMoD\n",
    "\n",
    "Configuration of the function approximator: Here the first argument is the number of input and the last argument the number of output layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NN(3, [50, 50, 50, 50], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration of the library function: We select athe library with a 2D spatial input. Note that that the max differential order has been pre-determined here out of convinience. So, for poly_order 1 the library contains the following 12 terms:\n",
    "* [$1, u_x, u_y, u_{xx}, u_{yy}, u_{xy}, u, u u_x, u u_y, u u_{xx}, u u_{yy}, u u_{xy}$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = Library2D(poly_order=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration of the sparsity estimator and sparsity scheduler used. In this case we use the most basic threshold-based Lasso estimator and a scheduler that asseses the validation loss after a given patience. If that value is smaller than 1e-5, the algorithm is converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Threshold(0.1)\n",
    "sparsity_scheduler = TrainTestPeriodic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration of the sparsity estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint = LeastSquares()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate the model and select the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepMoD(network, library, estimator, constraint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=2e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DeepMoD\n",
    "\n",
    "We can now run DeepMoD using all the options we have set and the training data:\n",
    "* The directory where the tensorboard file is written (log_dir)\n",
    "* The ratio of train/test set used (split)\n",
    "* The maximum number of iterations performed (max_iterations)\n",
    "* The absolute change in L1 norm considered converged (delta)\n",
    "* The amount of epochs over which the absolute change in L1 norm is calculated (patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24975  MSE: 2.79e-04  Reg: 1.20e-05  L1: 1.86e+00 Algorithm converged. Writing model to disk.\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    optimizer,\n",
    "    sparsity_scheduler,\n",
    "    log_dir=\"runs/2DAD/\",\n",
    "    max_iterations=25000,\n",
    "    delta = 10**-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity masks provide the active and non-active terms in the PDE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([False,  True,  True,  True,  True, False, False, False, False, False,\n",
       "         False, False])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sparsity_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator_coeffs gives the magnitude of the active terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.        ],\n",
       "        [0.3539985 ],\n",
       "        [0.71517855],\n",
       "        [0.3977614 ],\n",
       "        [0.38704312],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_coeffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
